# RF_US_DL
Scripts for processing B-mode ultrasound images of the rectus femoris using deep learning

# Overview
The goal of this project was to calculate fascicle lengths and pennation angles of the rectus femoris from B-mode ultrasound collected during walking with treadmill "slips" delivered in early and late stance. This repo contains the Matlab scripts used to automate that process in addition to some example data. 

The overall idea is to train deep learning networks to identify the superficial and deep aponeuroses after which the area between those aponeuroses is used to generate a representative fascicle.

# Workflow
# Part 1 – Aponeurosis Identification using Deep-Learning	
Part 1 of the application consists of 3 steps. 

First, an image set is generated to train and validate deep-learning models for identification of superficial and deep aponeuroses. The overarching design strategy of this approach is to “overfit” models to perform best on the remaining images of a study. This approach allows for rapid training of models with a small dataset on a mid-range desktop computer and avoids having to collect and manually track a data set that generalizes across tasks, probes, participants, etc. (Leitner et al., 2021). The drawback of this approach is that the trained models are likely study specific, limiting reproducibility. In this study, a set of 490 images was used for training and validating models. This image set consisted of 35 frames equally spaced in time across 1 perturbed gait cycle from both the ipsilateral and contralateral legs for all 7 participants. From the identified set of images, the superficial and deep aponeuroses are then manually traced to produce binary masks (roipoly, Matlab). 

The second step is training separate models for identification of pixels belonging to either superficial or deep aponeuroses. Both the raw images and masks are resized to 512x512 pixels for use in model training. A U-net model architecture is used based on previous success in identifying pixels corresponding to fascicles and aponeuroses (Cronin, 2020; Ritsche et al., 2023). For both the superficial and deep aponeurosis models, the total image set is first randomized, then split into training (80% of the image set) and validation sets (20% of the image set). In this study, each model took approximately 1 hour to train (trainNetwork, Matlab) on a desktop computer with an Nvidia GTX 1660 Ti graphics card. From the validation set, pixel-wise mean classification accuracies were 96% and 94% and mean intersection over union values were 94% and 91% for the superficial and deep aponeuroses, respectively. 

The third step is applying the trained models to the broader dataset (~111,000 frames) and generation of first order polynomials to represent the superficial and deep aponeuroses which defines the region of interest for fascicle detection. This is accomplished by generating masks of both the superficial and deep aponeuroses from each frame of ultrasound data using the trained models (semanticseg, Matlab), identifying the largest object by area in each of the predicted masks, and then fitting a first order polynomial based on the centroid and orientation of each identified object (regionprops, Matlab). The intersection points of these superficial and deep first order polynomials with the proximal and distal borders of the image serve as the vertices bounding the region of interest. These regions of interest are then used in Part 2.

# Part 2 – Representative Fascicle Estimation
A GUI-based Matlab application was developed to allow for streamlined visualization of representative fascicle measurements and correction of aponeurosis fits. The functionality of this application is separated into 4 steps. Example ultrasound data from dynamic trials is available at: https://zenodo.org/doi/10.5281/zenodo.12728475 in "ExampleUSData"

First, the raw images, with fascicles running from top left to bottom right, are filtered using adaptive histogram equalization (adapthisteq, Matlab) to improve contrast of hyperechoic structures. To account for angled images, the user is prompted to enter the image angle, which is used to first shear the image to have vertical edges, then applies adaptive histogram equalization (adapthisteq, Matlab), then returns the image to the original angle. This step is necessary as the border outside an angled image introduces artifacts during filtering. From the filtered image, the area between the aponeuroses is identified as the region of interest, with all structures outside of that area being removed. The region of interest is binarized (imbinarize, Matlab) using a Frangi-type vessel enhancement filter (fibermetric, Matlab; thickness = 7, sensitivity = 100) as has been used in previous tracking algorithms (Frangi et al., 1998; Ryan et al., 2019; van der Zee and Kuo, 2022). From this binarized image, the orientations and major axis lengths of each separate structure are computed (regionprops, Matlab). The user also has the option of further limiting the region of the image passed through to fascicle detection by applying an additional manual mask to these results, which may be warranted if the muscle of interest has compartments of different architectures. 

The second step is identification of the “snippets” in the binarized image which can be attributed to fascicles. Similar to (Marzilger et al., 2018), only structures with major axis lengths greater than 4 mm, area to length ratios less than 12, and with orientations relative to the deep aponeurosis within specified bounds are used to estimate the representative fascicle of each frame. The range of acceptable pennation angles relative to the deep aponeurosis was set between 6 and 20 degrees, based on in-vivo and cadaveric measurements of RF architecture (Blazevich et al., 2006; Ward et al., 2009) . 

The third step is assessment of the thickness of the muscle. This is calculated as the length of a line segment running perpendicular to the deep aponeurosis which intersects both the superficial aponeurosis and the midpoint of the deep aponeurosis. 

The fourth step is calculating representative fascicle parameters. The representative pennation angle of a frame is calculated as the circular mean weighted by snippet length from all accepted snippets, as adapted from (Marzilger et al., 2018). The representative fascicle length is then calculated as the thickness divided by the sine of this representative pennation angle (Blazevich et al., 2006; Ryan et al., 2019; van der Zee and Kuo, 2022). Following completed processing of a trial, the ensemble averaged and time normalized fascicle lengths and pennation angles are visualized.


